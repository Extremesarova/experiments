{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center>\n<img src=\"https://habrastorage.org/files/fd4/502/43d/fd450243dd604b81b9713213a247aa20.jpg\">\n## Open Machine Learning Course\n<center>Author: [Yury Kashnitsky](https://www.linkedin.com/in/festline/), Data Scientist at Mail.ru Group <br>\n    All content is distributed under the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license.\nYou may use this material for any purpose (you can edit, correct and use it as example) exept commercial use with mandatory citation of author.","metadata":{"_uuid":"fa68e17d12b944b5925f0f1f3b35de84f88b63e7"}},{"cell_type":"markdown","source":"# <center> Assignment #6 (demo).\n## <center>  Exploring OLS, Lasso and Random Forest in a regression task\n    \n<img src=https://habrastorage.org/webt/-h/ns/aa/-hnsaaifymavmmudwip9imcmk58.jpeg width=30%>\n\n**Fill in the missing code and choose answers in [this](https://docs.google.com/forms/d/1aHyK58W6oQmNaqEfvpLTpo6Cb0-ntnvJ18rZcvclkvw/edit) web form.**","metadata":{"_uuid":"d4fba24c2fc97c5651c8b229a864bd3e4fb9c80a"}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics.regression import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.linear_model import LinearRegression, LassoCV, Lasso\nfrom sklearn.ensemble import RandomForestRegressor","metadata":{"_uuid":"5a5dbe8ccaac5938472fffabd662570bbee580a5","execution":{"iopub.status.busy":"2021-11-26T06:34:48.881681Z","iopub.execute_input":"2021-11-26T06:34:48.882183Z","iopub.status.idle":"2021-11-26T06:34:49.776032Z","shell.execute_reply.started":"2021-11-26T06:34:48.882126Z","shell.execute_reply":"2021-11-26T06:34:49.775098Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"**We are working with UCI Wine quality dataset (no need to download it â€“ it's already there, in course repo and in Kaggle Dataset).**","metadata":{"_uuid":"42c346b2e75d1f1aad91a95e17994c541657c4e5"}},{"cell_type":"code","source":"data = pd.read_csv('../input/winequality-white.csv')","metadata":{"_uuid":"6fbd38aed5fa42e075b5d5a33e8e2da21807ad75","execution":{"iopub.status.busy":"2021-11-26T06:34:49.778165Z","iopub.execute_input":"2021-11-26T06:34:49.778557Z","iopub.status.idle":"2021-11-26T06:34:49.824436Z","shell.execute_reply.started":"2021-11-26T06:34:49.778469Z","shell.execute_reply":"2021-11-26T06:34:49.823722Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"_uuid":"0ca6a09adeecd4dc07b33e765baa4ea82820fe37","execution":{"iopub.status.busy":"2021-11-26T06:34:49.827311Z","iopub.execute_input":"2021-11-26T06:34:49.827665Z","iopub.status.idle":"2021-11-26T06:34:49.969440Z","shell.execute_reply.started":"2021-11-26T06:34:49.827607Z","shell.execute_reply":"2021-11-26T06:34:49.968526Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"_uuid":"8567888d41488b52f8b2d3dff80bd2d16c3df07d","execution":{"iopub.status.busy":"2021-11-26T06:34:49.971012Z","iopub.execute_input":"2021-11-26T06:34:49.971579Z","iopub.status.idle":"2021-11-26T06:34:49.986768Z","shell.execute_reply.started":"2021-11-26T06:34:49.971514Z","shell.execute_reply":"2021-11-26T06:34:49.985932Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"**Separate the target feature, split data in 7:3 proportion (30% form a holdout set, use random_state=17), and preprocess data with `StandardScaler`.**","metadata":{"_uuid":"40b24e1cbe39da5f25f6abdfa6f4dce01052eba2"}},{"cell_type":"code","source":"y = data['quality'] # you code here\nX = data.drop(['quality'], axis = 1)\nX_train, X_holdout, y_train, y_holdout = train_test_split(X, y, train_size=0.7, random_state=17)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_holdout_scaled = scaler.transform(X_holdout)","metadata":{"_uuid":"22991d1fcd912df4535ec8e0dd804d9d66b336f6","execution":{"iopub.status.busy":"2021-11-26T06:34:49.988321Z","iopub.execute_input":"2021-11-26T06:34:49.988991Z","iopub.status.idle":"2021-11-26T06:34:50.005026Z","shell.execute_reply.started":"2021-11-26T06:34:49.988919Z","shell.execute_reply":"2021-11-26T06:34:50.004179Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Linear regression","metadata":{"_uuid":"4323af0a23b5a874c7fb0fc3bcadeebefd5bdce1"}},{"cell_type":"markdown","source":"**Train a simple linear regression model (Ordinary Least Squares).**","metadata":{"_uuid":"39e8d88d30226a24ea1d62cfdf849b9a9b164a3f"}},{"cell_type":"code","source":"linreg = LinearRegression()\nlinreg.fit(X_train_scaled, y_train)","metadata":{"_uuid":"d228bb880c81ea10ad104e1f9685c8a2ee95ae97","execution":{"iopub.status.busy":"2021-11-26T06:34:50.006756Z","iopub.execute_input":"2021-11-26T06:34:50.007517Z","iopub.status.idle":"2021-11-26T06:34:50.176834Z","shell.execute_reply.started":"2021-11-26T06:34:50.007359Z","shell.execute_reply":"2021-11-26T06:34:50.175835Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**<font color='red'>Question 1:</font> What are mean squared errors of model predictions on train and holdout sets?**","metadata":{"_uuid":"143bd8c03bc75265fe317b7163ea9992fec72a52"}},{"cell_type":"code","source":"linreg_train_pred = linreg.predict(X_train_scaled)\nlinreg_holdout_pred = linreg.predict(X_holdout_scaled)\n\nmse_train = mean_squared_error(y_train, linreg_train_pred).round(3)\nmse_holdout = mean_squared_error(y_holdout, linreg_holdout_pred).round(3)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T07:00:19.233941Z","iopub.execute_input":"2021-11-26T07:00:19.234382Z","iopub.status.idle":"2021-11-26T07:00:19.243945Z","shell.execute_reply.started":"2021-11-26T07:00:19.234320Z","shell.execute_reply":"2021-11-26T07:00:19.242722Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"print(f\"Mean squared error (train) for linreg: {mse_train}\")\nprint(f\"Mean squared error (test) for linreg: {mse_holdout}\")","metadata":{"_uuid":"546f6310409fd0cced8e9cf9b5b9b647bc519b4a","execution":{"iopub.status.busy":"2021-11-26T07:00:31.628653Z","iopub.execute_input":"2021-11-26T07:00:31.629431Z","iopub.status.idle":"2021-11-26T07:00:31.636443Z","shell.execute_reply.started":"2021-11-26T07:00:31.628971Z","shell.execute_reply":"2021-11-26T07:00:31.635446Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"**Sort features by their influence on the target feature (wine quality). Beware that both large positive and large negative coefficients mean large influence on target. It's handy to use `pandas.DataFrame` here.**\n\n**<font color='red'>Question 2:</font> Which feature this linear regression model treats as the most influential on wine quality?**","metadata":{"_uuid":"eb150b4956b12f57d7a4d2a868b220d56951c70d"}},{"cell_type":"code","source":"d = dict(zip(X.columns, linreg.coef_))\nlinreg_coef = pd.DataFrame.from_records(sorted(d.items(), key=lambda item: np.abs(item[1]), reverse=True), columns=['features', 'coefficients']).set_index('features')\nlinreg_coef","metadata":{"execution":{"iopub.status.busy":"2021-11-26T06:34:50.220377Z","iopub.execute_input":"2021-11-26T06:34:50.221141Z","iopub.status.idle":"2021-11-26T06:34:50.266296Z","shell.execute_reply.started":"2021-11-26T06:34:50.220805Z","shell.execute_reply":"2021-11-26T06:34:50.265174Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Lasso regression","metadata":{"_uuid":"c8180a8be8a1c16db3b3a4b2f1b045360fffedb8"}},{"cell_type":"markdown","source":"**Train a LASSO model with $\\alpha = 0.01$ (weak regularization) and scaled data. Again, set random_state=17.**","metadata":{"_uuid":"ec78a7a6489c112634ab66ee3c8a64732333b255"}},{"cell_type":"code","source":"lasso1 = Lasso(alpha=0.01, random_state=17)\nlasso1.fit(X_train_scaled, y_train)","metadata":{"_uuid":"c93c9f0aef5c045104cd170a415f0138ecfde280","execution":{"iopub.status.busy":"2021-11-26T06:34:50.267872Z","iopub.execute_input":"2021-11-26T06:34:50.268228Z","iopub.status.idle":"2021-11-26T06:34:50.306223Z","shell.execute_reply.started":"2021-11-26T06:34:50.268169Z","shell.execute_reply":"2021-11-26T06:34:50.305152Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**Which feature is the least informative in predicting wine quality, according to this LASSO model?**","metadata":{"_uuid":"2ebc826e15035e973f142ea14529e9ea62f0eaae"}},{"cell_type":"code","source":"d = dict(zip(X.columns, lasso1.coef_))\nlasso1_coef = pd.DataFrame.from_records(sorted(d.items(), key=lambda item: np.abs(item[1])), columns=['features', 'coefficients']).set_index('features')\nlasso1_coef","metadata":{"_uuid":"a3e0123570f2bfc183e9af04fc09de4aa00a3e33","execution":{"iopub.status.busy":"2021-11-26T06:34:50.307852Z","iopub.execute_input":"2021-11-26T06:34:50.308238Z","iopub.status.idle":"2021-11-26T06:34:50.329913Z","shell.execute_reply.started":"2021-11-26T06:34:50.308177Z","shell.execute_reply":"2021-11-26T06:34:50.329218Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**Train LassoCV with random_state=17 to choose the best value of $\\alpha$ in 5-fold cross-validation.**","metadata":{"_uuid":"34daf26da8dc65ca9dea1390b1c990bdb1e746fe"}},{"cell_type":"code","source":"alphas = np.logspace(-6, 2, 200)\nlasso_cv = LassoCV(alphas=alphas, cv=5, random_state=17)\nlasso_cv.fit(X_train_scaled, y_train)","metadata":{"_uuid":"1261f3d8b86bf6b32a47f4fbd6421a224a32fb25","execution":{"iopub.status.busy":"2021-11-26T06:35:33.414574Z","iopub.execute_input":"2021-11-26T06:35:33.415087Z","iopub.status.idle":"2021-11-26T06:35:33.709203Z","shell.execute_reply.started":"2021-11-26T06:35:33.415018Z","shell.execute_reply":"2021-11-26T06:35:33.708214Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"lasso_cv.alpha_","metadata":{"_uuid":"11cfcfa256d3fadcc41c17c4a203980f43270f86","execution":{"iopub.status.busy":"2021-11-26T06:35:37.350179Z","iopub.execute_input":"2021-11-26T06:35:37.350465Z","iopub.status.idle":"2021-11-26T06:35:37.355911Z","shell.execute_reply.started":"2021-11-26T06:35:37.350409Z","shell.execute_reply":"2021-11-26T06:35:37.355067Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"**<font color='red'>Question 3:</font> Which feature is the least informative in predicting wine quality, according to the tuned LASSO model?**","metadata":{"_uuid":"774659494a9e10c5880a061b77f0ad4de3f6f48c"}},{"cell_type":"code","source":"d = dict(zip(X.columns, lasso_cv.coef_))\nlasso_cv_coef = pd.DataFrame.from_records(sorted(d.items(), key=lambda item: np.abs(item[1])), columns=['features', 'coefficients']).set_index('features')\nlasso_cv_coef","metadata":{"_uuid":"e48d180e412893f9b510a39edcf612d13a865dc9","execution":{"iopub.status.busy":"2021-11-26T06:36:01.436621Z","iopub.execute_input":"2021-11-26T06:36:01.437045Z","iopub.status.idle":"2021-11-26T06:36:01.454218Z","shell.execute_reply.started":"2021-11-26T06:36:01.436948Z","shell.execute_reply":"2021-11-26T06:36:01.453208Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"**<font color='red'>Question 4:</font> What are mean squared errors of tuned LASSO predictions on train and holdout sets?**","metadata":{"_uuid":"6784416717d86f9693adc016ebf2805d82e1f44f"}},{"cell_type":"code","source":"lasso_cv_train_pred = lasso_cv.predict(X_train_scaled)\nlasso_cv_holdout_pred = lasso_cv.predict(X_holdout_scaled)\n\nmse_train = mean_squared_error(y_train, lasso_cv_train_pred).round(3)\nmse_holdout = mean_squared_error(y_holdout, lasso_cv_holdout_pred).round(3)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T06:59:07.989480Z","iopub.execute_input":"2021-11-26T06:59:07.990101Z","iopub.status.idle":"2021-11-26T06:59:07.997910Z","shell.execute_reply.started":"2021-11-26T06:59:07.990039Z","shell.execute_reply":"2021-11-26T06:59:07.996952Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"print(f\"Mean squared error (train) for lasso_cv: {mse_train}\")\nprint(f\"Mean squared error (test) for lasso_cv: {mse_holdout}\")","metadata":{"_uuid":"8c1e912d29500bdd01232dffb7b7b12708a61354","execution":{"iopub.status.busy":"2021-11-26T06:59:08.287685Z","iopub.execute_input":"2021-11-26T06:59:08.288277Z","iopub.status.idle":"2021-11-26T06:59:08.293062Z","shell.execute_reply.started":"2021-11-26T06:59:08.288227Z","shell.execute_reply":"2021-11-26T06:59:08.292338Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest","metadata":{"_uuid":"cece55c36b4975456ac808ed60f80c4607bce364"}},{"cell_type":"markdown","source":"**Train a Random Forest with out-of-the-box parameters, setting only random_state to be 17.**","metadata":{"_uuid":"2b1d919f11b7552d1fd5218469049cbceb0c6b12"}},{"cell_type":"code","source":"forest = RandomForestRegressor(random_state=17)\nforest.fit(X_train_scaled, y_train)","metadata":{"_uuid":"ef3ab441dd993dbae6326026fa0b685ecb048e43","execution":{"iopub.status.busy":"2021-11-26T06:38:02.440610Z","iopub.execute_input":"2021-11-26T06:38:02.440943Z","iopub.status.idle":"2021-11-26T06:38:02.645351Z","shell.execute_reply.started":"2021-11-26T06:38:02.440876Z","shell.execute_reply":"2021-11-26T06:38:02.644452Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"**<font color='red'>Question 5:</font> What are mean squared errors of RF model on the training set, in cross-validation (cross_val_score with scoring='neg_mean_squared_error' and other arguments left with default values) and on holdout set?**","metadata":{"_uuid":"79d151e17dda0fa3667e01f5514edc9fa471a99f"}},{"cell_type":"code","source":"cross_val_score_result = abs(cross_val_score(forest, X_train_scaled, y_train, scoring='neg_mean_squared_error').mean())\nforest_train_pred = forest.predict(X_train_scaled)\nforest_holdout_pred = forest.predict(X_holdout_scaled)\n\nmse_train = mean_squared_error(y_train, forest_train_pred).round(3)\nmse_holdout = mean_squared_error(y_holdout, forest_holdout_pred).round(3)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T06:59:28.358297Z","iopub.execute_input":"2021-11-26T06:59:28.358903Z","iopub.status.idle":"2021-11-26T06:59:28.769456Z","shell.execute_reply.started":"2021-11-26T06:59:28.358853Z","shell.execute_reply":"2021-11-26T06:59:28.768570Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"print(\"Mean squared error (train) for forest: %.3f\" % mse_train)\nprint(\"Mean squared error (cv for forest): %.3f\" % cross_val_score_result)\nprint(\"Mean squared error (test) for forest: %.3f\" % mse_holdout)","metadata":{"_uuid":"78cb1562e5250e2c495954ed2f2007db4e9bd4ac","execution":{"iopub.status.busy":"2021-11-26T06:59:28.770878Z","iopub.execute_input":"2021-11-26T06:59:28.771182Z","iopub.status.idle":"2021-11-26T06:59:28.775940Z","shell.execute_reply.started":"2021-11-26T06:59:28.771122Z","shell.execute_reply":"2021-11-26T06:59:28.774877Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"**Tune the `max_features` and `max_depth` hyperparameters with GridSearchCV and again check mean cross-validation MSE and MSE on holdout set.**","metadata":{"_uuid":"cbfda28eb1ad4d6d0a8b640e6bcee1a6c2a0d83a"}},{"cell_type":"code","source":"forest_params = {'max_depth': list(range(10, 25)), \n                 'min_samples_leaf': list(range(1, 8)),\n                 'max_features': list(range(6,12))}\n\nlocally_best_forest = GridSearchCV(forest, param_grid=forest_params, n_jobs=-1, scoring='neg_mean_squared_error', verbose=True)\nlocally_best_forest.fit(X_train_scaled, y_train)","metadata":{"_uuid":"b8fcca3ab63a14e9ebe4e05f1b706affee19ec15","execution":{"iopub.status.busy":"2021-11-26T07:19:22.187405Z","iopub.execute_input":"2021-11-26T07:19:22.188069Z","iopub.status.idle":"2021-11-26T07:20:42.101545Z","shell.execute_reply.started":"2021-11-26T07:19:22.187667Z","shell.execute_reply":"2021-11-26T07:20:42.100559Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"locally_best_forest.best_params_, locally_best_forest.best_score_","metadata":{"_uuid":"daa31046bca781b63e8b08d941d270ed39cca694","execution":{"iopub.status.busy":"2021-11-26T07:21:03.654115Z","iopub.execute_input":"2021-11-26T07:21:03.654514Z","iopub.status.idle":"2021-11-26T07:21:03.662101Z","shell.execute_reply.started":"2021-11-26T07:21:03.654439Z","shell.execute_reply":"2021-11-26T07:21:03.661216Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"**<font color='red'>Question 6:</font> What are mean squared errors of tuned RF model in cross-validation (cross_val_score with scoring='neg_mean_squared_error' and other arguments left with default values) and on holdout set?**","metadata":{"_uuid":"f3b5f128ac9d25d6a2fe001e1b945d890e4e125a"}},{"cell_type":"code","source":"cross_val_score_result = abs(cross_val_score(locally_best_forest.best_estimator_, X_train_scaled, y_train, scoring='neg_mean_squared_error').mean()).round(3)\nlocally_best_forest_train_pred = locally_best_forest.predict(X_train_scaled)\nlocally_best_forest_holdout_pred = locally_best_forest.predict(X_holdout_scaled)\n\nmse_train = mean_squared_error(y_train, locally_best_forest_train_pred).round(3)\nmse_holdout = mean_squared_error(y_holdout, locally_best_forest_holdout_pred).round(3)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T07:21:07.126697Z","iopub.execute_input":"2021-11-26T07:21:07.127430Z","iopub.status.idle":"2021-11-26T07:21:07.423290Z","shell.execute_reply.started":"2021-11-26T07:21:07.127366Z","shell.execute_reply":"2021-11-26T07:21:07.422355Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"print(f\"Mean squared error (cv) for locally_best_forest: {cross_val_score_result}\")\nprint(f\"Mean squared error (test) for locally_best_forest: {mse_holdout}\")","metadata":{"_uuid":"8b1c78727baa4caa5e5de4fc99289f9c38a78eca","execution":{"iopub.status.busy":"2021-11-26T07:21:07.424611Z","iopub.execute_input":"2021-11-26T07:21:07.424862Z","iopub.status.idle":"2021-11-26T07:21:07.429722Z","shell.execute_reply.started":"2021-11-26T07:21:07.424818Z","shell.execute_reply":"2021-11-26T07:21:07.429121Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"**Output RF's feature importance. Again, it's nice to present it as a DataFrame.**<br>\n**<font color='red'>Question 7:</font> What is the most important feature, according to the Random Forest model?**","metadata":{"_uuid":"2edaca791a764dcbd8c255c622046a3262c9d343"}},{"cell_type":"code","source":"d = dict(zip(X.columns, locally_best_forest.best_estimator_.feature_importances_))\nlocally_best_forest_feature_importances = pd.DataFrame.from_records(sorted(d.items(), key=lambda item: np.abs(item[1]), reverse=True), columns=['features', 'coefficients']).set_index('features')\nlocally_best_forest_feature_importances","metadata":{"_uuid":"c5fc1d874ba41c152e0c1dd11eba469320a91613","execution":{"iopub.status.busy":"2021-11-26T06:55:29.607010Z","iopub.execute_input":"2021-11-26T06:55:29.607375Z","iopub.status.idle":"2021-11-26T06:55:29.628319Z","shell.execute_reply.started":"2021-11-26T06:55:29.607318Z","shell.execute_reply":"2021-11-26T06:55:29.627226Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"**Make conclusions about the performance of the explored 3 models in this particular prediction task.**","metadata":{"_uuid":"bc3c0e87a735ef74b1d1de869dd8ceae9fa42f9a"}},{"cell_type":"markdown","source":"Mean squared error (train) for linreg: 0.558 <br />\nMean squared error (test) for linreg: 0.584\n\nMean squared error (train) for lasso_cv: 0.558 <br />\nMean squared error (test) for lasso_cv: 0.583 <br />\n\nMean squared error (train) for forest: 0.075 <br />\nMean squared error (cv for forest): 0.460 <br />\nMean squared error (test) for forest: 0.422\n\nMean squared error (cv) for locally_best_forest: 0.453 <br />\nMean squared error (test) for locally_best_forest: 0.417 \n\nPerformance of Lasso (L1 regularized regression) is just slightly better than the performance of simple linear regression. Whereas random forest regression improves the result of linear regression greatly and by tuning the parameters results on a train and a test set can be improved even further. \n\n**It means that probably the dependency between wine quality and the features is non-linear.**\n\n\nWhat can be done next:\n* Checking Ridge regression\n* Analysing feature importances and linear regression coefficients\n\nThe main conclusion for solving all the supervised learning tasks - for determining baseline for the task first check all easily available variants because it is hard to guess which algorithm will prove yourself best for the task. ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}