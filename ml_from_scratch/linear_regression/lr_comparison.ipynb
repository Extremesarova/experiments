{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "First, let's import needed modules and set random seed (we'll use it if needed)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from linear_regression import SciPyLinearRegressionOLS, LinearRegressionOLS, \\\n",
    "    SciPyLinearRegressionNNOLS\n",
    "from utils.scaler import Scaler\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading california housing dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X, y = fetch_california_housing(return_X_y=True, as_frame=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Splitting data into training and testing dataset (10% for test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Standardize features by removing the mean and scaling to unit variance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "scaler = Scaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First solution will use the analytical solution to OLS to get the weights/coefficients: $\\hat{\\beta} = (X^TX)^{-1}(X^TY)$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients are [ 0.84355454  0.11881471 -0.27379819  0.29731402 -0.00432302 -0.04037888\n",
      " -0.88437955 -0.85609482]\n",
      "The intercept is 2.0708738533591724\n"
     ]
    }
   ],
   "source": [
    "ols_reg = LinearRegressionOLS()\n",
    "ols_reg.fit(X_train_scaled, y_train)\n",
    "print(f\"The coefficients are {ols_reg.coef_}\")\n",
    "print(f\"The intercept is {ols_reg.intercept_}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Second solution is the sklearn's solution"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Second' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-11-a6f54f1b7009>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mSecond\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'Second' is not defined"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "sklearn_ols_reg = LinearRegression(positive=False)\n",
    "sklearn_ols_reg.fit(X_train_scaled, y_train)\n",
    "print(f\"The coefficients are {sklearn_ols_reg.coef_}\")\n",
    "print(f\"The intercept is {sklearn_ols_reg.intercept_}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients are [ 0.84355454  0.11881471 -0.27379819  0.29731402 -0.00432302 -0.04037888\n",
      " -0.88437955 -0.85609482]\n",
      "The intercept is 2.0708738533591733\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see the results are the same, because sklearn is using <code>scipy.linalg.lstsq</code> method under it's hood. Which, also, wrapped by me below:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients are [ 0.84355454  0.11881471 -0.27379819  0.29731402 -0.00432302 -0.04037888\n",
      " -0.88437955 -0.85609482]\n",
      "The intercept is 2.0708738533591657\n"
     ]
    }
   ],
   "source": [
    "scipy_ols_reg = SciPyLinearRegressionOLS()\n",
    "scipy_ols_reg.fit(X_train_scaled, y_train)\n",
    "print(f\"The coefficients are {scipy_ols_reg.coef_}\")\n",
    "print(f\"The intercept is {scipy_ols_reg.intercept_}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The results are expectedly the same\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we specify <code>positive=False</code> when initializing <code>sklearn.linear_model.LinearRegression</code> object, then sklearn will use <code>scipy.optimize.nnls</code> method"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients are [0.82427902 0.23207778 0.         0.006524   0.03701429 0.\n",
      " 0.         0.        ]\n",
      "The intercept is 2.0708738533591733\n"
     ]
    }
   ],
   "source": [
    "sklearn_ols_reg_pos = LinearRegression(positive=True)\n",
    "sklearn_ols_reg_pos.fit(X_train_scaled, y_train)\n",
    "print(f\"The coefficients are {sklearn_ols_reg_pos.coef_}\")\n",
    "print(f\"The intercept is {sklearn_ols_reg_pos.intercept_}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Which is naturally equal to the results from the wrapped method"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients are [0.82427902 0.23207778 0.         0.006524   0.03701429 0.\n",
      " 0.         0.        ]\n",
      "The intercept is 2.070873853359181\n"
     ]
    }
   ],
   "source": [
    "scipy_nn_ols_reg = SciPyLinearRegressionNNOLS()\n",
    "scipy_nn_ols_reg.fit(X_train_scaled, y_train)\n",
    "print(f\"The coefficients are {scipy_nn_ols_reg.coef_}\")\n",
    "print(f\"The intercept is {scipy_nn_ols_reg.intercept_}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO:\n",
    " - the idea of regularization and why it is needed\n",
    " - using gradient descent instead of using formula (analytical solution)\n",
    " - comparing results of SGDRegressor with results of ridge regression\n",
    " - in which situations using gradient descent is more advisable\n",
    " - R2 and adjusted R2\n",
    " - Linear regression metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients are [  0.57504629   0.14611444   0.26600053  -0.18758554   0.12954952\n",
      " -15.09777784  -1.76790904  -1.60107809]\n",
      "The intercept is [1.9034144]\n"
     ]
    }
   ],
   "source": [
    "sklearn_sgd_reg = SGDRegressor()\n",
    "sklearn_sgd_reg.fit(X_train_scaled, y_train)\n",
    "print(f\"The coefficients are {sklearn_sgd_reg.coef_}\")\n",
    "print(f\"The intercept is {sklearn_sgd_reg.intercept_}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}